# ğŸ§  ollamaâ€‘cliâ€‘agent

*A privacy-first, terminal-based AI assistantâ€”with real-time web access, persistent memory, and local LLM intelligence.*

---

## ğŸš€ Features

- **Local LLM** via Ollama + llama.cpp (`ChatOllama`)  
- **Live Web Search**: SerpAPI, Brave Search  
- **Full-page Scraping**: FireCrawl, scraped -> ingested  
- **Long-term Memory**: Qdrant vector store for retrieval-augmented responses  
- **Terminal-first Interface**: ingest, search, fetch, askâ€”all from your CLI  

---

## ğŸ›  Installation

```bash
# 1. Clone the repo
git clone https://github.com/<your-username>/ollama-cli-agent.git
cd ollama-cli-agent

# 2. Setup Micromamba environment
micromamba create -n ollama-cli-agent python=3.11 -y
micromamba activate ollama-cli-agent

# 3. Install Python dependencies
pip install -r requirements.txt

# 4. Configure API keys (optional)
cp .env.sample .env
# Edit .env to add:
# SERPAPI_API_KEY=...    # For Google search
# BRAVE_API_KEY=...      # For Brave search
# FIRECRAWL_API_KEY=...  # For web scraping

# 5. Install and run Ollama
# Visit https://ollama.ai to install Ollama
# Then pull a model:
ollama pull mistral:7b  # Default model
ollama pull all-minilm  # Embedding model
```

---

## âš¡ Quick Start

### Starting the Assistant

```bash
# Activate the environment
micromamba activate ollama-cli-agent

# Run the assistant
python assistant.py

# Or with custom model
python assistant.py --model llama2:7b

# Or with debug logging
python assistant.py --debug
```

### Using the Assistant

Once started, you'll see the `You>` prompt. Here are the available commands:

#### ğŸ“ **ask** - Ask questions to the AI
```
You> ask What is Python?
You> ask Explain machine learning in simple terms
You> ask How do I create a REST API?
```

#### ğŸ’¾ **ingest** - Add content to memory
```
You> ingest The capital of France is Paris
You> ingest https://example.com/article
You> ingest Python is a high-level programming language
```

#### ğŸ” **search** - Search the web
```
You> search latest AI news
You> search Python tutorials for beginners
You> search OpenAI GPT-4 features
```

#### ğŸŒ **fetch** - Fetch and display web content
```
You> fetch https://python.org
You> fetch https://github.com/trending
```

#### ğŸ“Š **stats** - View memory statistics
```
You> stats
```

#### â“ **help** - Show available commands
```
You> help
```

#### ğŸ‘‹ **exit** - Exit the assistant
```
You> exit
---

## ğŸ§© Project Structure

```
ollama-cli-agent/
â”œâ”€â”€ assistant.py          # Entry point - CLI interface
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent.py         # Core agent logic
â”‚   â”œâ”€â”€ assistant.py     # CLI command handlers
â”‚   â””â”€â”€ qdrant_store.py  # Vector database interface
â”œâ”€â”€ web_tools/
â”‚   â”œâ”€â”€ serpapi_tool.py  # Google search via SerpAPI
â”‚   â”œâ”€â”€ brave_tool.py    # Brave search integration
â”‚   â””â”€â”€ firecrawl_tool.py # Web scraping tool
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logging.py       # Logging configuration
â”œâ”€â”€ tests/               # Unit and integration tests
â”œâ”€â”€ .env.sample          # API keys template
â””â”€â”€ requirements.txt     # Python dependencies
```

---

## ğŸ§­ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ assistant.py â”‚ â‡„ â”‚   agent.py    â”‚ â‡„ â”‚  Qdrant Memory â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ CLI             â”‚ LLM & tools            â”‚ Vector DB
       â”‚ (input/output)  â”‚ Search & fetch         â”‚ Persistent memory
       â”‚                 â”‚ (SerpAPI, Brave, FireCrawl)
```

### ğŸ’¾ Memory & Tools

**Memory**: 
- Uses Ollama embeddings (all-minilm model)
- Qdrant vector store for semantic search
- Persistent context across sessions

**Web Tools**:
- **SerpAPI**: Google search results
- **Brave Search**: Privacy-focused web search
- **FireCrawl**: Full-page content extraction

---

## ğŸ”§ Configuration

### Environment Variables (.env)
```bash
# Optional - for web search capabilities
SERPAPI_API_KEY=your_serpapi_key
BRAVE_API_KEY=your_brave_key
FIRECRAWL_API_KEY=your_firecrawl_key

# Qdrant settings (optional)
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION=ollama_cli_agent
```

### Ollama Models
The assistant uses:
- **LLM**: `mistral:7b` (default) - for text generation
- **Embeddings**: `all-minilm` - for vector embeddings

You can use any Ollama-supported model:
```bash
# List available models
ollama list

# Pull alternative models
ollama pull llama2:13b
ollama pull codellama:7b

# Use with assistant
python assistant.py --model llama2:13b
```

---

## ğŸ§ª Testing

```bash
# Run all tests
python -m unittest discover tests -v

# Run specific test file
python -m unittest tests.test_assistant -v

# Run with coverage (install coverage first)
pip install coverage
coverage run -m unittest discover tests
coverage report
```

---

## ğŸš¨ Troubleshooting

### Common Issues

1. **"Ollama not found" error**
   - Make sure Ollama is installed and running: `ollama serve`
   - Check if models are pulled: `ollama list`

2. **"Model not found" error**
   - Pull the required models: `ollama pull mistral:7b && ollama pull all-minilm`

3. **Web search not working**
   - Check if API keys are set in `.env` file
   - Verify API keys are valid and have credits

4. **Memory/Qdrant issues**
   - For development, Qdrant runs in-memory (no setup needed)
   - For persistent storage, run: `docker run -p 6333:6333 qdrant/qdrant`

---

## ğŸ¯ Roadmap

- [ ] ğŸ”’ Persistent Qdrant storage configuration
- [ ] ğŸŒ Additional web tools (Wikipedia, arXiv)
- [ ] ğŸ“ Export conversation history
- [ ] ğŸ”„ Streaming responses
- [ ] ğŸ¨ Rich terminal UI with colors
- [ ] ğŸ”Œ Plugin system for custom tools

ğŸ§¹ Auto-fetch + ingest top search results

ğŸ›  Enhanced CLI UX: help, command autocompletion

ğŸ”Œ Plugin support (e.g., Git integration)

ğŸŒ Optional web UI via Chainlit

âœ… Contributing & License
Welcome contributions! Submit issues or PRs.

Licensed under MIT License.

ğŸ§  About This Project
Built to be modular, terminal-first, private, and easy to extendâ€”perfect for demos, portfolios, or personal productivity workflows.

